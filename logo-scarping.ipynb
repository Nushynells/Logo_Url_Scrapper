{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"E:/Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvCompanies=pd.read_csv(\"list2.csv\", encoding= 'unicode_escape')\n",
    "\n",
    "#Replace nulls with empty strings\n",
    "csvCompanies.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvCompanies['website'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csvCompanies.dropna(subset=['website'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "output=[]# This will hold all the dictionaries representing all rows of data\n",
    "for link in df['website']:\n",
    "    #find the index of the row e.g. website link on the first row will be 0\n",
    "    \n",
    "#     loc=df[df[\"website\"]==link].index[0] #This slows down the loop even if by microsecond.\n",
    "#     print(link)\n",
    "    \n",
    "        #send request to speed it up make it async\n",
    "#     print(x, link) ==>Wanted to see which link fails and after how many checks\n",
    "    try:#Ensuring the failing doesn't stop your code\n",
    "        page=requests.get(link,allow_redirects=True)# The fail is coming from here. \n",
    "\n",
    "            #get the beautifulsoup object of the page\n",
    "        soup=BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        for img_el in soup.find_all('img'):\n",
    "            src_value = img_el.get('src', 'src not available')\n",
    "            if 'logo' in src_value.lower(): #or img_el['alt']:\n",
    "                data = {'website' : link, 'logo': src_value}#if the index value isn't of importance.\n",
    "#                 df[\"logo\"].loc[loc]=src_value #==> This eats a lot of time\n",
    "            else:\n",
    "                pass\n",
    "    except:# If there is an error do this. Usually used to see what kind of error occured\n",
    "        data = {'website' : link, 'logo': \"URL Failed\"}\n",
    "#         print(link, \" ==>failed\")\n",
    "    output.append(data)\n",
    "#     x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output)# Convert your list of dictionaries to a dataframe\n",
    "output_df.to_csv(path_or_buf=\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
